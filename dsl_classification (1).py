# -*- coding: utf-8 -*-
"""dsl classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AmF9gbwrC1EeFT0PQTUwdTunAaXlJ5rA
"""

import pandas as pd
df = pd.read_csv("/content/development.csv")

df.head()

df.dtypes

df.shape

"""# **PREPROCESSING OF DATA**"""

dfn = df

dfn.columns

"""checking for null columns"""

dfn.isnull().sum()

"""Here i dropped ID,RACE AND EDU  as ID is unnecessary for prediction while race will create potential bias and Edu column has no relation with predicting death and also it has significant number of null values"""

dfn1 = dfn.drop('Id',axis =1)

dfn2 = dfn1.drop('race',axis = 1)

dfn3 = dfn2.drop('edu',axis= 1)

"""checking for data types if the columns have same data types or different"""

dfn3.dtypes

"""we find out that sex,dzgroup,dzclass,income,ca,dnr have different datatypes.
So, now i check the unique values of of each column to find out a solution to fix it .
"""

dfn3['sex'].unique()

dfn3['sex'] = dfn3['sex'].map({'male':0 , 'female':1})

dfn3.dtypes

"""i decided to one-hot encoding here for dzclass ,ca and dnr ."""

list = ['dzclass','ca']
for i in list:
  print(dfn3[i].unique())

import numpy as np
dfn4 = pd.get_dummies(data=dfn3, columns=['dzclass','ca','dnr'],dtype=np.float64)

"""rest of the columns of different datatypes have significant null values so before going ahead we check for distribution."""

import matplotlib.pyplot as plt
for i in dfn4.columns:
     plt.figure()
     dfn4[i].hist()
     plt.suptitle(i)
     plt.show()

"""Here we observed the columns dzgoup,income,prg2m,prg6m have significant number of null values and also the distribution is not normal."""

dfn5 = dfn4.drop('dzgroup',axis = 1)

dfn6 = dfn5.drop('income',axis =1)

dfn7 = dfn6.drop('prg2m',axis = 1)

dfn8 = dfn7.drop('prg6m', axis = 1)

dfn8.shape

dfn8.columns

"""here i used simple imputer to fill the null values"""

import numpy as np
from sklearn.impute import SimpleImputer
imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')
from sklearn.compose import ColumnTransformer

imputer = SimpleImputer(strategy="mean")
imputed_df = pd.DataFrame(imputer.fit_transform(dfn8), columns=dfn8.columns)

imputed_df.isnull().sum()

"""# **Now we create a model by using appropriate hyperparameters and train it.**

"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
x = imputed_df.drop('death',axis = 1)
y = imputed_df['death']
xtrain,xtest,ytrain,ytest = train_test_split(x,y,train_size=0.8,random_state = 42,stratify=y)

"""Finding appropriate hyperparameters dont run its only for finding  hyperparameters."""

from sklearn.metrics import f1_score
for n_estimators in range(10, 300,10):
  for max_depth in range(10,200,10):
     clf = RandomForestClassifier(n_estimators,max_depth =max_depth ,random_state=42,class_weight='balanced',criterion = 'log_loss')
     clf.fit(xtrain, ytrain)
     f1s = clf.score(xtest, ytest)
     if f1s >= 0.76:
          print(n_estimators,f1s,max_depth)

clf = RandomForestClassifier(n_estimators= 30,max_depth = 30 ,random_state=42,class_weight='balanced',criterion = 'log_loss')
clf.fit(xtrain, ytrain)
f1s = clf.score(xtrain,ytrain)

print(f1s)

y_pred = clf.predict(xtest)

from sklearn.metrics import f1_score
f1_score(ytest,y_pred,average='macro')

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
print(classification_report(ytest, y_pred))

from sklearn.metrics import confusion_matrix
import seaborn as sns
cm = confusion_matrix(ytest, y_pred)
cm_df = pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])

plt.figure(figsize=(8, 6))
sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('Actual Labels')
plt.show()

print(cm_df)

import numpy as np
importances = clf.feature_importances_
feature_names = imputed_df.columns




indices_sorted = importances.argsort()[::-1]
threshold = 0.015


important_features = [feature_names[indices_sorted[i]] for i in range(len(indices_sorted)) if importances[indices_sorted[i]] > threshold]


print("Important Features (above threshold):")

print("Feature Importances:")
for i in range(len(indices_sorted)):
    print(f"{imputed_df.columns[indices_sorted[i]]}: {importances[indices_sorted[i]]}")


import matplotlib.pyplot as plt

plt.figure(figsize=(20, 9))
plt.bar(range(imputed_df.shape[1]), importances[indices_sorted])
plt.xticks(range(imputed_df.shape[1]), imputed_df.columns[indices_sorted], rotation=45, ha="right")
plt.xlabel("Feature")
plt.ylabel("Importance")
plt.title("Feature Importances")
plt.show()

print(important_features)

"""compairing the results of different models."""

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, f1_score
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn import tree

models = [
    ('Random Forest', RandomForestClassifier(class_weight='balanced', random_state=42)),
    ('SVM', SVC(kernel='rbf', class_weight='balanced', random_state=42)),
    ('Logistic Regression', LogisticRegression(class_weight='balanced', random_state=42)),
    ('k-NN', KNeighborsClassifier()),
    ('Naive Bayes', GaussianNB()),
    ('decision tree', tree.DecisionTreeClassifier())
]

results = []
names = []

for name, model in models:
    cv_results = cross_val_score(model, xtrain, ytrain, cv=5, scoring='f1_macro', n_jobs=-1)
    results.append(cv_results)
    names.append(name)
    print(f"{name}: {cv_results.mean():.4f} ({cv_results.std():.4f})")


plt.boxplot(results, labels=names)
plt.title('Model Comparison')
plt.xlabel('Model')
plt.ylabel('F1 Score')
plt.show()

"""HERE we observed even without doing any hyperparameter tuning randomforest worked well then other classification method so we decided to stay with randomforest for training and prediction.

finally predicting Evaluation dataset
"""

import pandas as pd
edf = pd.read_csv('/content/evaluation.csv')

edf.shape

edf.head()

"""Here also i followed the same process which is needed for data preprocessing."""

edf1 = edf
edf1['sex'] = edf['sex'].map({'male':0 , 'female':1})

edf2 = pd.get_dummies(data=edf1, columns=['dzclass','ca','dnr'],dtype=np.float64)

edf3 = edf2.drop('race',axis =1)

edf4 = edf3.drop('Id',axis =1)

edf5 = edf4.drop('edu',axis =1)

edf6 = edf5.drop('dzgroup',axis = 1)

edf7 = edf6.drop('income',axis = 1)

edf8 =  edf7.drop('prg2m',axis = 1)

edf9 = edf8.drop('prg6m',axis = 1)

import numpy as np
from sklearn.impute import SimpleImputer
imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')
from sklearn.compose import ColumnTransformer

imputer = SimpleImputer(strategy="mean")
imputed_df = pd.DataFrame(imputer.fit_transform(edf9), columns=edf9.columns)

rounded_predictions =clf.predict(imputed_df)

ids = edf['Id'].values

formatted_predictions = ["{}".format(x) for x in rounded_predictions]

"""Creating file for submission."""

submission_df = pd.DataFrame({
    'Id': ids,
    'Predicted': formatted_predictions
})

submission_df.to_csv('submission13.csv', index=False)